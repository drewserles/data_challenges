{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session for notebook\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'paytmteam-de-weather-challenge/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=spark.read.csv(data_path+'data/2019', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------+----+----+------+------+-----+----+-----+----+-----+-----+-----+-----+------+\n",
      "|STN---| WBAN|YEARMODA|TEMP|DEWP|   SLP|   STP|VISIB|WDSP|MXSPD|GUST|  MAX|  MIN| PRCP| SNDP|FRSHTT|\n",
      "+------+-----+--------+----+----+------+------+-----+----+-----+----+-----+-----+-----+-----+------+\n",
      "|010260|99999|20190101|26.1|21.2|1001.9| 987.5| 20.6| 9.0| 15.9|29.7| 29.8|21.7*|0.02G| 18.5|001000|\n",
      "|010260|99999|20190102|24.9|22.1|1020.1|1005.5|  5.4| 5.6| 13.6|22.1|27.1*| 20.7|0.48G| 22.8|001000|\n",
      "|010260|99999|20190103|31.7|29.1|1008.9| 994.7| 13.6|11.6| 21.4|49.5|37.4*|26.8*|0.25G|999.9|011000|\n",
      "|010260|99999|20190104|32.9|30.3|1011.4| 997.1| 15.8| 4.9|  7.8|10.9| 36.1| 31.8|0.52G|999.9|001000|\n",
      "|010260|99999|20190105|35.5|33.0|1015.7|1001.4| 12.0|10.4| 13.6|21.0|38.5*| 32.7|0.02G| 23.6|010000|\n",
      "+------+-----+--------+----+----+------+------+-----+----+-----+----+-----+-----+-----+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4158416"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get full station-country info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Station and Country lists\n",
    "station = spark.read.csv(data_path+'stationlist.csv', header=True)\n",
    "country = spark.read.csv(data_path+'countrylist.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|STN_NO|COUNTRY_ABBR|\n",
      "+------+------------+\n",
      "|012240|          NO|\n",
      "|020690|          SW|\n",
      "|020870|          SW|\n",
      "|021190|          SW|\n",
      "|032690|          UK|\n",
      "+------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "station.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+\n",
      "|COUNTRY_ABBR|       COUNTRY_FULL|\n",
      "+------------+-------------------+\n",
      "|          AA|              ARUBA|\n",
      "|          AC|ANTIGUA AND BARBUDA|\n",
      "|          AF|        AFGHANISTAN|\n",
      "|          AG|            ALGERIA|\n",
      "|          AI|   ASCENSION ISLAND|\n",
      "+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25306, 288)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station.count(), country.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "stn_cntry = station.join(country, on='COUNTRY_ABBR', how='left_outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note an inner join gives 25,209 rows here. There are some country abbreviations in the station dataset not covered in the country set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25306"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stn_cntry.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join global data with station information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the station number from the global data\n",
    "data = data.withColumnRenamed('STN---', 'STN_NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.join(stn_cntry, on='STN_NO', how='left_outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4161334"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It looks like there are 366 days for this year. Not a leap year though\n",
    "df.select('YEARMODA').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|max(YEARMODA)|min(YEARMODA)|\n",
      "+-------------+-------------+\n",
      "|     20200101|     20190101|\n",
      "+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contains the first day of 2020 in the dataset. I want to remove that.\n",
    "df.agg(F.max('YEARMODA'), F.min('YEARMODA')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter((df.YEARMODA >= 20190101) & (df.YEARMODA <= 20191231))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also the miss entry for station number is has many measurements. Since I don't know what country these belong\n",
    "# to I will remove them completely\n",
    "day_count = df.groupBy('STN_NO').agg(F.count(F.lit(1)).alias('num_days'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|STN_NO|num_days|\n",
      "+------+--------+\n",
      "|999999|   75225|\n",
      "|785510|     730|\n",
      "|788660|     730|\n",
      "|917920|     730|\n",
      "|789900|     730|\n",
      "|785140|     730|\n",
      "|789880|     730|\n",
      "|788730|     730|\n",
      "|785265|     716|\n",
      "|153000|     365|\n",
      "+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "day_count.orderBy('num_days', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move this to data cleaning\n",
    "df = df.filter(df.STN_NO != 999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|STN_NO|num_days|\n",
      "+------+--------+\n",
      "|871271|       1|\n",
      "|649300|       1|\n",
      "|406220|       1|\n",
      "|111370|       1|\n",
      "|227270|       1|\n",
      "|112340|       1|\n",
      "|854520|       1|\n",
      "|618020|       1|\n",
      "|766810|       1|\n",
      "|627510|       1|\n",
      "+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Note there are a lot of stations with few measurements.\n",
    "day_count.orderBy('num_days').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Country with the hottest average mean temperature over the year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want the average of the mean temperatures. That's the 'TEMP' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4083991"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = df.select('STN_NO', 'YEARMODA', 'TEMP', 'COUNTRY_ABBR', 'COUNTRY_FULL').distinct()\n",
    "temp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|STN_NO|num_days|\n",
      "+------+--------+\n",
      "|917920|     730|\n",
      "|785510|     730|\n",
      "|789900|     730|\n",
      "|785140|     730|\n",
      "|789880|     730|\n",
      "|788660|     730|\n",
      "|788730|     730|\n",
      "|785265|     716|\n",
      "|722678|     365|\n",
      "|153000|     365|\n",
      "+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_agg = temp.groupBy('STN_NO').agg(F.count(F.lit(1)).alias('num_days')).orderBy('num_days', ascending=False)\n",
    "temp_agg.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12143, 6859)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_agg.count(), temp_agg.filter(temp_agg.num_days==365).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----+------------+--------------------+\n",
      "|STN_NO|YEARMODA|TEMP|COUNTRY_ABBR|        COUNTRY_FULL|\n",
      "+------+--------+----+------------+--------------------+\n",
      "|788660|20190101|78.9|          NN|                null|\n",
      "|788660|20190101|78.9|          NT|NETHERLANDS ANTILLES|\n",
      "+------+--------+----+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp.filter((temp.STN_NO == 788660) & (temp.YEARMODA==20190101)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still a few minor problems/duplicate station entries. I'm going to clean up the data by making some assumptions.\n",
    "1. Remove the country name Null\n",
    "2. Remove the no-record value for the TEMP column, which is 9999.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.filter((temp.STN_NO != 999999) & (temp.COUNTRY_FULL.isNotNull()) & (temp.TEMP != 9999.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4083991"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculation for average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation\n",
    "avg_temp = temp.groupBy('COUNTRY_ABBR', 'COUNTRY_FULL').agg(F.avg('TEMP').alias('temp'), F.count(F.lit(1)).alias('rec_cnt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------------+-------+\n",
      "|COUNTRY_ABBR|        COUNTRY_FULL|             temp|rec_cnt|\n",
      "+------------+--------------------+-----------------+-------+\n",
      "|          DJ|            DJIBOUTI|90.06114457831325|    332|\n",
      "|          OD|                null|88.38571428571429|     21|\n",
      "|          CD|                CHAD|87.36099706744866|   2728|\n",
      "|          NG|               NIGER|85.06022291247945|   5473|\n",
      "|          SU|               SUDAN| 84.4549418604651|   1032|\n",
      "|          ES|         EL SALVADOR|84.44045944678854|   2133|\n",
      "|          TV|              TUVALU|84.32217090069284|    433|\n",
      "|          JU| JUAN DE NOVA ISLAND|84.15945945945947|     37|\n",
      "|          TL|             TOKELAU|83.96142857142854|     70|\n",
      "|          IO|BRITISH INDIAN OC...|83.91150684931505|    365|\n",
      "|          CJ|      CAYMAN ISLANDS|83.77780821917811|    730|\n",
      "|          UV|        BURKINA FASO|83.74875078076202|   3202|\n",
      "|          MV|            MALDIVES|83.67879452054797|   1825|\n",
      "|          SN|           SINGAPORE|83.63278538812786|   1095|\n",
      "|          CB|            CAMBODIA|83.49766803840879|    729|\n",
      "|          ML|                MALI|83.38503218884121|   3728|\n",
      "|          VC|ST. VINCENT AND T...|83.35714285714286|     84|\n",
      "|          RM|    MARSHALL ISLANDS|83.24358974358974|   1131|\n",
      "|          FM|          MICRONESIA|83.22937823834197|   1930|\n",
      "|          AE|                null|83.19267183738967|   3739|\n",
      "+------------+--------------------+-----------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_temp.orderBy('temp', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this data I'm seeing that the country with the hottest average temperature over 2019 was Djibouti, with a temp of 90.1F. It should be noted that it only has 332 records, which is not even one measurement each day from a single weather station.\n",
    "\n",
    "It would need to be considered what portion of the year was covered and by how many stations to decide if this was an accurate picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Which country has the most consecutive days of tornados/funnel cloud formation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the 6th digit in the FRSHTT column. I'm going to assume that if a country has tornado formation at any of its weather station it counts for the country as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last digit is 1 when there's a tornado. Use a modulo 2 to extract this digit into a new column for a tornado flag\n",
    "df = df.withColumn('tornado', F.col('FRSHTT') % 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|FRSHTT|tornado|\n",
      "+------+-------+\n",
      "|011010|    0.0|\n",
      "|010000|    0.0|\n",
      "|000000|    0.0|\n",
      "|010000|    0.0|\n",
      "|010000|    0.0|\n",
      "+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.tornado==0).select('FRSHTT', 'tornado').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|FRSHTT|tornado|\n",
      "+------+-------+\n",
      "|010011|    1.0|\n",
      "|000011|    1.0|\n",
      "|010011|    1.0|\n",
      "|010001|    1.0|\n",
      "|010001|    1.0|\n",
      "+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.tornado==1).select('FRSHTT', 'tornado').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by country code and day. Give the country a 1 for tornado formation if there was a tornado detected at\n",
    "# one of the weather stations\n",
    "tornado = df.groupBy('YEARMODA', 'COUNTRY_ABBR').agg(F.max('tornado').alias('ntnl_tornado'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+------------+\n",
      "|YEARMODA|COUNTRY_ABBR|ntnl_tornado|\n",
      "+--------+------------+------------+\n",
      "|20190818|          NO|         0.0|\n",
      "|20190820|          NO|         0.0|\n",
      "|20190204|          FI|         0.0|\n",
      "|20190123|          UK|         0.0|\n",
      "|20190325|          SZ|         0.0|\n",
      "+--------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tornado.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to create a window function to find the streaks of tornado days.\n",
    "\n",
    "I'm running out of time here - but my plan was to partition by country and order by date. Then start counting a streak. If the current day did not have a tornado then reset the streak to 0. If the current day did have a tornado, continue the streak. If there was a lost measurement (i.e. gap between days was > 1) then make an assumption that the streak was reset, and take the current days value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only need to keep the days where there was a tornado\n",
    "tornado = tornado.filter(tornado.ntnl_tornado == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+------------+\n",
      "|YEARMODA|COUNTRY_ABBR|ntnl_tornado|\n",
      "+--------+------------+------------+\n",
      "|20190124|          IT|         1.0|\n",
      "|20190607|          IN|         1.0|\n",
      "|20190124|          JA|         1.0|\n",
      "|20190914|          BD|         1.0|\n",
      "|20190113|          US|         1.0|\n",
      "|20190816|          IN|         1.0|\n",
      "|20191031|          SC|         1.0|\n",
      "|20190115|          SC|         1.0|\n",
      "|20190806|          BF|         1.0|\n",
      "|20190611|          NO|         1.0|\n",
      "|20190514|          MT|         1.0|\n",
      "|20190418|          TU|         1.0|\n",
      "|20191108|          CJ|         1.0|\n",
      "|20191107|          IT|         1.0|\n",
      "|20191111|          US|         1.0|\n",
      "|20190405|          AO|         1.0|\n",
      "|20191204|          JA|         1.0|\n",
      "|20191029|          PE|         1.0|\n",
      "|20190810|          JA|         1.0|\n",
      "|20191109|          IT|         1.0|\n",
      "+--------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tornado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of days between records - needs to be consecutive.\n",
    "day_window = Window.partitionBy('COUNTRY_ABBR').orderBy('YEARMODA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "tornado = tornado.withColumn('day_gap', F.col('YEARMODA') - F.lag(F.col('YEARMODA')).over(day_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+------------+-------+\n",
      "|YEARMODA|COUNTRY_ABBR|ntnl_tornado|day_gap|\n",
      "+--------+------------+------------+-------+\n",
      "|20190923|          AA|         1.0|   null|\n",
      "|20190704|          AG|         1.0|   null|\n",
      "|20190206|          AO|         1.0|   null|\n",
      "|20190405|          AO|         1.0|  199.0|\n",
      "|20190510|          AR|         1.0|   null|\n",
      "|20190120|          AU|         1.0|   null|\n",
      "|20190616|          AU|         1.0|  496.0|\n",
      "|20190619|          AU|         1.0|    3.0|\n",
      "|20191014|          AU|         1.0|  395.0|\n",
      "|20191019|          AU|         1.0|    5.0|\n",
      "+--------+------------+------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tornado.orderBy('COUNTRY_ABBR', 'YEARMODA').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My next step here would be to find the groups of continues days, then calculate which group had the most rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Second highest average mean wind speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be looking at the WDSP column to calculate averages, and remove the no-record value of 999.9. It's important here because there are many no records and it's heavily skewing the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4083991"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3958697"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the no record value for windspeed\n",
    "wind = df.filter(df.WDSP != 999.9)\n",
    "wind.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_wind = wind.groupBy('COUNTRY_ABBR', 'COUNTRY_FULL').agg(F.avg('WDSP').alias('wdsp'), F.count(F.lit(1)).alias('rec_cnt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+------------------+-------+\n",
      "|COUNTRY_ABBR|        COUNTRY_FULL|              wdsp|rec_cnt|\n",
      "+------------+--------------------+------------------+-------+\n",
      "|          FK|FALKLAND ISLANDS ...| 17.87783300198807|   2012|\n",
      "|          AA|               ARUBA|15.981917808219173|    365|\n",
      "|          FO|       FAROE ISLANDS| 15.28067010309278|    776|\n",
      "|          FS|FRENCH SOUTHERN A...|14.203721841332031|   1021|\n",
      "|          BB|            BARBADOS|14.101643835616441|    365|\n",
      "|          SB|ST. PIERRE AND MI...| 13.90767123287671|    365|\n",
      "|          CV|          CAPE VERDE| 13.61522184300341|   1465|\n",
      "|          TE|     TROMELIN ISLAND|13.005277777777751|    360|\n",
      "|          SH|          ST. HELENA|12.730518394648827|   1196|\n",
      "|          MR|          MAURITANIA|12.723464912280699|    456|\n",
      "|          AY|          ANTARCTICA| 12.27517270608179|  23595|\n",
      "|          SO|             SOMALIA|12.274880611270296|   1047|\n",
      "|          CK|COCOS (KEELING) I...|12.054545454545453|    363|\n",
      "|          GK|            GUERNSEY|12.018019257221466|    727|\n",
      "|          IM|        MAN  ISLE OF|11.893424657534247|    365|\n",
      "|          MH|          MONTSERRAT|11.808813559322036|    295|\n",
      "|          UC|                null| 11.73616438356165|    365|\n",
      "|          IC|             ICELAND|11.734775540827808|  15994|\n",
      "|          WI|      WESTERN SAHARA|11.647547169811322|   1060|\n",
      "|          ST|           ST. LUCIA|11.579726027397257|    730|\n",
      "+------------+--------------------+------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_wind.orderBy('WDSP', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm seeing that ARUBA had the second highest average wind speed over the year at 16.0 Knots with 365 measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
